{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75df07",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn_extra'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn_extra\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMedoids\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m silhouette_score\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn_extra'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "data = pd.read_csv(\"../data/preprocessed_data.csv\")\n",
    "data.info()\n",
    "def cluster_data(df, features=None, k_range=range(2, 11), max_samples=10000, random_state=42, verbose=True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Sample Of Data\n",
    "    sample_size = min(len(df), max_samples)\n",
    "    samples = df.sample(n=sample_size, random_state=random_state)  \n",
    "    \n",
    "    # Search for best K\n",
    "    scores = []\n",
    "    labels_dict = {}\n",
    "    \n",
    "    # LOOP\n",
    "    for k in k_range:\n",
    "    \n",
    "        kmedoids = KMedoids(n_clusters=k, random_state=random_state, metric='euclidean')\n",
    "        labels = kmedoids.fit_predict(samples)\n",
    "        labels_dict[k] = labels\n",
    "        medoids_dict = {k: kmedoids}\n",
    "        \n",
    "        #silhouette score\n",
    "        score = silhouette_score(samples, labels)\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Find optimal k (skip k=1 if it's in the range)\n",
    "    best_k = k_range[scores.index(max(scores))]\n",
    "\n",
    "    df_clustered = df.copy()\n",
    "\n",
    "    # Add Cluster Column to Data\n",
    "    df_clustered.loc[samples.index, 'Cluster'] = labels_dict[best_k] \n",
    "    \n",
    "    # Get the best model\n",
    "    best_kmedoids = KMedoids(n_clusters=best_k, random_state=random_state).fit(samples)\n",
    "    \n",
    "    if len(df_clustered) > sample_size:\n",
    "\n",
    "        # Assign remaining points to nearest medoid center\n",
    "        remaining_indices = df_clustered.index.difference(samples.index)\n",
    "        remaining_data = df.loc[remaining_indices]\n",
    "\n",
    "        # Predict clusters for remaining points\n",
    "        remaining_labels = best_kmedoids.predict(remaining_data)\n",
    "        df_clustered.loc[remaining_indices, 'Cluster'] = remaining_labels\n",
    "    \n",
    "    return df_clustered, best_k, scores\n",
    "def analyze_clusters(df, cluster_col='Cluster'):\n",
    "\n",
    "    features = df.select_dtypes(include='number').columns.drop(cluster_col)\n",
    "\n",
    "    print(df[cluster_col].value_counts().sort_index())\n",
    "    return df.groupby(cluster_col)[features].mean()\n",
    "X = data.drop(columns=['Category'])  # Numerical Data\n",
    "Y = data['Category']\n",
    "\n",
    "df_clustered, best_k, scores = cluster_data(X)  \n",
    "\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "cluster_means = analyze_clusters(df_clustered)\n",
    "print(cluster_means)\n",
    "\n",
    "df_clustered.info()\n",
    "df_clustered[\"Category\"]=data[\"Category\"]\n",
    "df_clustered.columns\n",
    "df_clustered.to_csv(\"../data/Kmedoid_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
